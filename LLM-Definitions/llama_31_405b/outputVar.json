[
    {
        "name": "response",
        "description": "Contains the text generated by the LLM",
        "level": "nominal",
        "type": "string",
        "length": 5000
    },
    {
        "name": "run_time",
        "description": "Inference time of the LLM",
        "level": "interval",
        "type": "decimal",
        "length": 8
    },
    {
        "name": "prompt_length",
        "description": "Token amount of the prompt input",
        "level": "interval",
        "type": "decimal",
        "length": 8
    },
    {
        "name": "output_length",
        "description": "Token amount of the LLM output",
        "level": "interval",
        "type": "decimal",
        "length": 8
    }
]