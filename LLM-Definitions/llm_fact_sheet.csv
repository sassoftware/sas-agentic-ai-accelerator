model_id,model,provider,description,release_date,size,deployment_type,license,cost_type,input_token_price,output_token_price,second_cost,context_length,temperature,top_p,top_k,max_tokens,knowledge_cut_off
"claude_2_0","Claude 2.0","Anthropic","Claude 2 was released by Anthropic in 2023 and is available via their APIs or via AWS Bedrock. The exact parameter count is not know and is only estimated.",2023-07-11,130000000000,"API","Propietary","Tokens",0.000003,0.000015,.,100000,1,1,.,1000,2023-01-01
"claude_2_1","Claude 2.1","Anthropic","Claude 2.1 delivers advancements in key capabilities for enterprises—including an industry-leading 200K token context window, significant reductions in rates of model hallucination, system prompts and our new beta feature: tool use.",2023-11-21,130000000000,API,Propietary,Tokens,0.000008,0.000024,.,200000,1,1,.,1000,2023-01-01
"claude_haiku_3","Claude Haiku 3","Anthropic","Claude 3 Haiku, the fastest and most affordable model in its intelligence class. With state-of-the-art vision capabilities and strong performance on industry benchmarks, Haiku is a versatile solution for a wide range of enterprise applications.",2024-03-13,20000000000,API,Propietary,Tokens,0.00000025,0.00000125,.,200000,1,1,.,1000,2023-08-01
"claude_opus_3","Claude Opus 3","Anthropic","Opus, our most intelligent model, outperforms its peers on most of the common evaluation benchmarks for AI systems, including undergraduate level expert knowledge (MMLU), graduate level expert reasoning (GPQA), basic mathematics (GSM8K), and more. It exhibits near-human levels of comprehension and fluency on complex tasks, leading the frontier of general intelligence.",2024-03-04,2000000000000,API,Propietary,Tokens,0.000015,0.000075,.,200000,1,1,.,1000,2023-08-01
"claude_sonnet_3","Claude Sonnet 3","Anthropic","Claude 3 Sonnet strikes the ideal balance between intelligence and speed—particularly for enterprise workloads. It delivers strong performance at a lower cost compared to its peers, and is engineered for high endurance in large-scale AI deployments.",2024-03-04,70000000000,API,Propietary,Tokens,0.000003,0.000015,.,200000,1,1,.,1000,2023-08-01
"claude_sonnet_3_5","Claude Sonnet 3.5","Anthropic","Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model, Claude 3 Sonnet.",2024-06-21,175000000000,API,Propietary,Tokens,0.000003,0.000015,.,200000,1,1,.,1000,2024-04-01
"gemini_flash_15_001","Gemini Flash 1.5 v001","Google",Gemini 1.5 Flash is a fast and versatile multimodal model for scaling across diverse tasks.,2024-05-24,20000000000,API,Propietary,Tokens,0.000000075,0.0000003,.,1048576,1,0.95,40,256,2024-01-01
"gemini_falsh_15_002","Gemini Flash 1.5 v002","Google",Gemini 1.5 Flash is a fast and versatile multimodal model for scaling across diverse tasks.,2024-09-24,20000000000,API,Propietary,Tokens,0.000000075,0.0000003,.,1048576,1,0.95,40,256,2024-05-01
"gemini_flash_15_8b","Gemini Flash 1.5 8B","Google",Gemini 1.5 Flash-8B is a small model designed for lower intelligence tasks.,2024-09-24,8000000000,API,Propietary,Tokens,0.0000000375,0.000000075,.,1048576,1,0.95,40,256,2024-05-01
"gemini_pro_15","Gemini Pro 1.5","Google","Gemini 1.5 Pro is a mid-size multimodal model that is optimized for a wide-range of reasoning tasks. 1.5 Pro can process large amounts of data at once, including 2 hours of video, 19 hours of audio, codebases with 60,000 lines of code, or 2,000 pages of text.",2024-09-24,200000000000,API,Propietary,Tokens,0.00000125,0.0000025,.,2097152,1,0.95,40,256,2024-05-01
"gemini_pro_25","Gemini Pro 2.5","Google","Gemini 2.5 Pro is our state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.",2025-06-01,200000000000,API,Propietary,Tokens,0.00000125,0.00001,.,1048576,1,0.95,40,256,2025-01-01
gemini_flash_25,Gemini Flash 2.5,Google,"Our best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.",2025-06-01,20000000000,API,Propietary,Tokens,0.0000003,0.0000025,.,1048576,1,0.95,40,256,2025-01-01
gemini_flash_lite_25,Gemini Flash Lite 2.5,Google,A Gemini 2.5 Flash model optimized for cost-efficiency and high throughput.,2025-06-01,20000000000,API,Propietary,Tokens,0.0000001,0.0000004,.,1048576,1,0.95,40,256,2025-01-01
"gpt_4o_2024_05_13","GPT 4o 2024-05-13","OpenAI","GPT-4ois our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.",2024-05-13,200000000000,API,Propietary,Tokens,0.00000125,0.00001,.,128000,1,1,.,.,2023-10-01
"gpt_4o_mini_2024_07_18","GPT 4o mini 2024-07-18","OpenAI","GPT-4ois our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.",2024-07-18,8000000000,API,Propietary,Tokens,0.00000015,0.0000006,.,128000,1,1,.,.,2023-10-01
"gpt_4o_mini_2025_01_01","GPT 4o mini 2025-01-01","OpenAI","GPT-4ois our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.",2025-01-01,8000000000,API,Propietary,Tokens,0.00000015,0.0000006,.,128000,1,1,.,.,2023-10-01
"llama_31_405b","Llama 3.1 405B","Meta","Llama 3.1 405B is the first openly available model that rivals the top AI models when it comes to state-of-the-art capabilities in general knowledge, steerability, math, tool use, and multilingual translation.",2024-07-23,405000000000,API,Llama 3.1,Tokens,0.000003,0.000003,.,128000,0.6,.,.,1024,2023-12-01
"llama_32_1b","Llama 3.2 1B","Meta","The Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.",2024-09-24,1230000000,SCR,Llama 3.2,Seconds,.,.,0.000039178,128000,0.6,1,.,256,2023-12-01
"llama_32_3b","Llama 3.2 3B","Meta","The Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.",2024-09-24,3210000000,SCR,Llama 3.2,Seconds,.,.,0.000069178,128000,0.6,1,.,256,2023-12-01
"mistral_nemo","Mistral Nemo","Mistral","Mistral NeMo, a 12B model built in collaboration with NVIDIA. Mistral NeMo offers a large context window of up to 128k tokens. Its reasoning, world knowledge, and coding accuracy are state-of-the-art in its size category.",2024-07-18,12000000000,SCR,Apache 2.0,Seconds,.,.,0.000069178,128000,0.3,.,.,256,2024-04-01
"phi_3_mini_4k","Phi 3 Mini 4k","Microsoft","We are excited to introduce Phi-3, a family of open AI models developed by Microsoft. Phi-3 models are the most capable and cost-effective small language models (SLMs) available, outperforming models of the same size and next size up across a variety of language, reasoning, coding, and math benchmarks.",2024-04-23,3800000000,SCR,MIT,Seconds,.,.,0.000039178,4000,.,.,.,2048,2023-10-01
"phi_35_mini","Phi 3.5 Mini","Microsoft","The Phi-3 model collection is the latest in Microsoft's family of Small Language Models (SLMs). They are designed to be highly capable and cost-effective, outperforming models of similar and larger sizes across various benchmarks in language, reasoning, coding, and math.",2024-08-22,3800000000,SCR,MIT,Seconds,.,.,0.000039178,128000,.,.,.,2048,2023-10-01
"qwen_25_05b","Qwen 2.5 0.5B","Alibaba Cloud","Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters.",2024-09-19,500000000,SCR,Apache 2.0,Seconds,.,.,0.000039178,128000,1,1,.,256,2024-08-01
"qwen_25_7b","Qwen 2.5 7B","Alibaba Cloud","Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters.",2024-09-19,7000000000,SCR,Apache 2.0,Seconds,.,.,0.000069178,128000,1,1,.,256,2024-08-01
"qwen_25_15b","Qwen 2.5 1.5B","Alibaba Cloud","Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters.",2024-09-19,1500000000,SCR,Apache 2.0,Seconds,.,.,0.000039178,128000,1,1,.,256,2024-08-01
"smollm_17b","SmolLM 1.7B","Hugging Face","SmolLM is a series of small language models available in three sizes: 135M, 360M, and 1.7B parameters.",2024-07-16,1700000000,SCR,Apache 2.0,Seconds,.,.,0.000039178,2048,0.6,0.92,.,100,2024-06-01
"smollm_135m","SmolLM 135M","Hugging Face","SmolLM is a series of small language models available in three sizes: 135M, 360M, and 1.7B parameters.",2024-07-16,135000000,SCR,Apache 2.0,Seconds,.,.,0.000039178,2048,0.6,0.92,.,100,2024-06-01
"smollm_360m","SmolLM 360M","Hugging Face","SmolLM is a series of small language models available in three sizes: 135M, 360M, and 1.7B parameters.",2024-07-16,360000000,SCR,Apache 2.0,Seconds,.,.,0.000039178,2048,0.6,0.92,.,100,2024-06-01